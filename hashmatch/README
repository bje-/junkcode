hashmatch - find common code
============================

Andrew Tridgell (tridge@samba.org)

This is a utility to help you find common code between two source
trees. It can be run in a number of ways, including in a manner where
two source trees can be compared by two people, both of whom do not
have access to the other ones source tree. In this way it can be
useful to help determine if two source trees contain common code
without revealing the contents of the source trees between the two
parties.

You can get the latest version of hashmatch from
http://samba.org/~tridge/hashmatch/. That is also a bzr URL, so you
can grab it like this:

  bzr branch http://samba.org/~tridge/hashmatch

Limitations
-----------

As with all matching algorithms there are two main types of errors,
false positives and false negatives. By choosing the right parameters
you can strike a balance between how many false positives and false
negatives you get from this utility.

The algorithm used is based on token matching, which means if the two
source trees have been modified sufficiently that few tokens match
then hashmatch won't find any common code. In that case a matching
algorithm based on the syntax tree of the code may be more
appropriate.

Of course, all hashmatch can do is generate candidates. The final
determination for whether code is really the same must be done by a
human. So you need an experienced programmer to look at the output of
hashmatch (probably with several different sets of parameters) then to
study the highlighted areas and determine which ones need further
investigation.


Usage
-----

There are 3 programs that come with this utility. They are:

  - blockhash: generate a set of hashes for a code tree
  - hashmatch: match a set of hashes against another code tree
  - hashmatch2: match two sets of hashes against each other

You will always need to use blockhash, then you can choose whether you
use hashmatch or hashmatch2 depending on your needs.

Using blockhash
---------------

You run blockhash like this:

  ./blockhash [options] SOURCEDIR1 > dir1.hash

The options you pass to blockhash are very important. The options are:

        -w token_width
        -s token_skip
        -a
        -p PATTERN

The default token_width is 7. Use a wider token_width to get less
false positives, at the risk of more false negatives. Using a wider
token_width also reduces the amount of information about a source tree
that could potentially be revealed by a hash file.

The default token_skip is 5. Use a smaller token_skip to get less
false negatives, at the price of a larger hash file and at the risk of
revealing more information about the source files in the hash. If you
don't care about revealing information about the source files in the
hash, and you have plenty of disk space, then a token_skip of 1 is
best.

Use the -a switch to include annotation information (source file and
line number) in the hash file. This will give much more useful output,
but obviously reveals information about the source code in the hash.

Use the -p option to restrict which files to look at. For example,
using -p '*.[chSs]' would be good for typical C source trees.

Using hashmatch
---------------

The hashmatch utility takes a hash file generated by blockhash and a
2nd source tree and finds matches. It generates a one column output in
either curses or HTML format. The output will show sections of code
from the given source tree which are good candidates for matching code
from the source tree used to generate the hash file. 

A simple usage would be as follows:

 ./hashmatch -H dir1.hash SOURCEDIR2 > matches.html

the -H option specifies the output as HTML. Use hashmatch -h for
other options. The important options are:

        -m match_threshold  set match threshold (default 1)
        -f fuzz_threshold   set fuzz threshold (default 5)
        -A                  avoid self matches
        -H                  produce HTML output
        -C                  produce curses output
        -p PATTERN          set filename wildcard pattern

The -p option is the same as for blockhash. You will probably want "-p '*.[chSs]'"
for C source code.

The -m option chooses the match threshold. A higher number means more
false negatives, and less false positives. 

The fuzz_threshold determines how many lines apart matches can be
while still considered to be part of the one match. A higher number
will give more false positives and less false negatives.

The -A option is used when you are matching source trees to themselves
(to find repeated code). It then eliminates matches with the same
source path.

In the output, the bits highlighted in red are the parts that actually
matched. Hashmatch will also put out a few lines of code on either
side of each match, to give the reader some context.


Using hashmatch2
----------------

hashmatch2 uses a slightly different algorithm, and produces a two
column output. The two column output is useful as it shows you the
pieces of matching code in the context of both source trees. This is
only useful when you have direct access to both trees, but if you do
have both trees then the output is much more useful, and it is
generally faster to eliminate false matches than with the hashmatch
output.

To run hashmatch2 you need two hash files from blockhash, and they
must be sorted. So for example you could use this:

  ./blockhash [options] SOURCEDIR1 | sort -r > dir1.hash

Note that the sort must be with -r.

You then run hashmatch2 with the two hash files. It only produces html
output.


Algorithm
---------

The algorithm is based on hashing groups of N tokens from the first
source tree, and finding matching groups of tokens in the second tree
that have the same hash. 

The first step is to 'tokenise' the first tree by dividing it up at
'word' boundaries delimited by a alphanumeric to non-alphanumeric
transitions, with all groups of whitespace characters collapsed to a
single character.

These tokens are then placed in groups of 'token_width' tokens, with
an overlap between neighboring token groups defined by a 'token_skip'
parameter. The default values for 'token_width' and 'token_skip' are
7 and 5 respectively, meaning that groups consist of 7 consecutive
tokens and neighboring groups start 5 tokens apart (with an overlap
of 2 tokens).

Each of these token groups is then hashed with a 128 bit MD4 hash, to
produce a file containing a list of hashes. The Unix sort program is
then used to sort the hashes and remove any duplicate entries. An
optional 'annotation' option is available at this stage which tells
the program to annotate the hashes with the source filename and line
number that each hash corresponds with. 

At the end of this stage of processing a file like the following is produced:

    version 1.0 of blockhash
    token_width 7
    token_skip 5
    FFFFF129E167A5113DAC12AE66E89374
    FFFFCFCFEFA4401FCCC322AC55A791C4
    FFFFB53566ADA7223275A254E32E3509
    FFFFB53566ADA7223275A254E32E3509
    FFFF871CE874A1E8ABE509FC80D8C589
    FFFF7F9E1B7265F983C296B718C34E23
    FFFF00AC27762B063041C8D7A8478F0A
    FFFED76ABB8280620AB19F1041AA1407

the file is quite large, often several hundred megabytes, with the
size depending primarily on the value of token_skip that has been
chosen and the size of the source tree.

This file is then used as the input for the second stage of
processing, which is to find pieces of code in the second tree that
match the hashes. The matching program traverses the second source
tree producing the same type of tokenised block hashes, but with a
token_skip of 1. Each hash is compared to every hash from the first
tree using an efficient indexed lookup algorithm. When a match is
found the program applies a number of heuristics to determine if the
match is likely to be significant. The parameters for these heuristics
can be easily set by the operator of the program.

The specific heuristics used include omitting very short matches,
based on the number of adjacent lines that contain a match. A second
heuristic determines how many lines can separate two matches before
they are considered to be separate blocks of matching code as opposed
to a single block.

Finally the program outputs a HTML rendering of the matches that have
been found, showing the file and line numbers, plus the lines in the
second tree that were found to match, with all of the groups of tokens
within each line that formed each match highlighted in red. This
allows the operator to quickly determine exactly why the program
considered that a match had occurred.


Technical considerations
------------------------

There are two quite separate conditions under which you might use this
program. The first occurs where you want to ensure that the hash file
produced from the first stage of processing contains the minimum
amount of identifiable information about the first source tree. This
mode of operation woud occur, for example, where you wished to provide
the hash file to a 3rd party that may not be able to view the source
tree and you want to ensure that they cannot recreate the source tree
from the hash file.

In this 'obfuscated' case it is important to choose a token_skip value
of sufficient size to prevent a determined attacker from recovering
the first source tree. I believe that a token_skip value of 10 would
be sufficient for this purpose, but I think if this is important it
would be prudent to have a suitably qualified theoretician examine the
algorithm to see if that is indeed sufficient. It should be noted that
a larger value of token_skip will also have the effect of reducing the
number of matches found, and could lead to some significant matches
being missed.

The second mode of operation is when there is no concern of revealing
the source code in the first tree in the hashes. In that case a
token_skip value of 1 should be chosen, and the 'annotate' option
should be enabled. This will produce a much larger hash file but will
maximise the chances of finding common code and will allow the source
file of the match in the first source tree to be quickly identified.

False positives and False negatives
-----------------------------------

It is of course possible for this program to find matches which are
not significant from an intellectual property standpoint and to miss
matches that may be significant. These are called 'false positives'
and 'false negatives' respectively.

The main source of false positives is insignificant pieces of matching
code. The use of sequences of numbers or particular formatting strings
that are widely used by programmers is unlikely to be significant and
thus would be considered a false positive. It is usually very easy to
determine these types of matches by eye.

False negatives are also possible, usually bacause the matching pieces
of code are too small to fall within a block hash group (as determined
by the token_width) or because closely spaced significant alteration
has occurred between the two instances of the code. The occurrance of
false negatives can be minimised with approriate use of the
token_width and token_skip parameters, but at the expense of an
increase in false positives.

